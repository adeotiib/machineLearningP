{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "dataset = pd.read_csv(\"UNSW_2018_IoT_Botnet_Final_10_Best.csv\", sep=';')\n",
    "del dataset['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['pkSeqID'], axis = 1)\n",
    "\n",
    "dataset.head() # shows the result after dropping unimportant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "plt.title('Dataset Features with Null Value')\n",
    "sns.heatmap(dataset.isnull()[:-1],yticklabels=False,cbar=False,cmap='hot', linecolor='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,4))\n",
    "sns.set_style('whitegrid')\n",
    "sns.displot(dataset['mean'],kde=False,color='darkred',bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = dataset.columns[dataset.dtypes.eq('object')]\n",
    "characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cols_to_convert = ['proto', 'saddr', 'sport', 'daddr', 'dport', 'category', 'subcategory']\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in cols_to_convert:\n",
    "    dataset[col] = dataset[col].astype(str)  # Convert column to string\n",
    "    dataset[col] = le.fit_transform(dataset[col])\n",
    "\n",
    "real_data = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange\n",
    "arra = list(real_data.columns.values) \n",
    "arra.pop(arra.index('attack')) \n",
    "real_data = real_data[arra+['attack']]\n",
    "real_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_data.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanaced dataset\n",
    "plt.figure(figsize=(10,4))\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='attack',data=real_data,palette='Set2_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "real_data[real_data['attack']==1]['mean'].hist(alpha=0.5,color='red',\n",
    "                                              bins=30,label='Fraudulent vs Mean Value=True')\n",
    "plt.legend()\n",
    "plt.xlabel('Bad network with Mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of phished and non-phished examples\n",
    "neg = real_data[real_data[\"attack\"] == 1].shape[0]\n",
    "pos = real_data[real_data[\"attack\"] == 0].shape[0]\n",
    "print(f\"Non-Fraudulent = {pos}\")\n",
    "print(f\"Fraudulent = {neg}\")\n",
    "print(f\"Ratio of non-Fraudulent networks against Fraudulent networks = {(pos / neg) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks the number of columns with string\n",
    "data = real_data.columns[real_data.dtypes.eq('object')]\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just for assurance to remove nan value\n",
    "real_data.dropna(axis=0)\n",
    "real_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=real_data.iloc[:,:-1].values\n",
    "y=real_data.iloc[:, -1].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance using mutual information\n",
    "importance = mutual_info_classif(X, y)\n",
    "\n",
    "# Create a DataFrame to store feature importance\n",
    "feat_importance = pd.Series(importance, real_data.columns[0:len(real_data.columns)-1])\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(20, 5))\n",
    "feat_importance.plot(kind='bar', color='r') \n",
    "plt.title('Feature Selection Using Mutual Information Algorithm')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Available features')\n",
    "plt.legend(['Importance to dependent variable'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store feature importance\n",
    "feat_importance = pd.Series(importance, real_data.columns[:-1])\n",
    "\n",
    "# Filter features based on the chosen threshold\n",
    "threshold = 0.05\n",
    "selected_features = feat_importance[feat_importance < threshold].index.tolist()\n",
    "\n",
    "# Drop features below the threshold from new_data\n",
    "new_data = real_data.drop(columns=[col for col in real_data.columns if col in selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.iloc[:,:].drop(['attack'] , axis=1)\n",
    "y=new_data['attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of RamdomOverSampler\n",
    "rand_oversampler = RandomOverSampler()\n",
    "X_train, y_train = rand_oversampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = LinearSVC(penalty='l2', max_iter=10000)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(f'SVM Accuracy based on validation Dataset {100*accuracy_score(y_test,y_pred):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(confusion_matrix(y_test,y_pred),annot=True, fmt='g')\n",
    "plt.ylabel('Actual Value')\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.title('SVM Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(19,activation='relu'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy','mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train,y=y_train,\n",
    "          validation_data=(X_test,y_test),\n",
    "          callbacks=[early_stop],\n",
    "          batch_size=64,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()\n",
    "plt.plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= (model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.heatmap(confusion_matrix(y_test,pred),annot=True, fmt='g')\n",
    "plt.ylabel('Actual Value')\n",
    "plt.xlabel('Predicted Value')\n",
    "plt.title('DNN Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "pred_prob = svm._predict_proba_lr(X_test)\n",
    "pred_prob1 = model.predict(X_test)\n",
    "\n",
    "# roc curve for models\n",
    "fpr, tpr, thresh = roc_curve(y_test, pred_prob[:,1], pos_label=1)\n",
    "fpr1, tpr1, thresh1 = roc_curve(y_test, pred_prob1, pos_label=1)\n",
    "\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "svm_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, svm_probs, pos_label=1)\n",
    "\n",
    "# roc curve for tpr = fpr \n",
    "model_probs = [0 for i in range(len(y_test))]\n",
    "p_fpr, p_tpr, _ = roc_curve(y_test, model_probs, pos_label=1)\n",
    "\n",
    "# auc scores\n",
    "auc_score = roc_auc_score(y_test, pred_prob[:,1])\n",
    "auc_score1 = roc_auc_score(y_test, pred_prob1)\n",
    "\n",
    "\n",
    "print('AUC Score of the developed model\\n')\n",
    "print(f'The AUC score for the SVM is :{auc_score}:\\nThe AUC score for the ANN is :{auc_score1}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Without Spearman Ranking\n",
    "plt.plot(fpr, tpr, linestyle='--',color='orange', label='SVM Model')\n",
    "plt.plot(fpr1, tpr1, linestyle='--',color='green', label='ANN Model')\n",
    "\n",
    "\n",
    "# plot for 50% probability (no skill classifier)\n",
    "plt.plot(p_fpr, p_tpr, linestyle='--', color='black')\n",
    "\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
